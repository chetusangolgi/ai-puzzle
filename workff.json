{
      "5": {
        "inputs": {
          "width": ["216", 1],
          "height": ["216", 2],
          "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
          "title": "Empty Latent Image"
        }
      },
      "6": {
        "inputs": {
          "text": ["270", 0],
          "clip": ["228", 1]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Prompt)"
        }
      },
      "13": {
        "inputs": {
          "noise": ["25", 0],
          "guider": ["22", 0],
          "sampler": ["16", 0],
          "sigmas": ["17", 0],
          "latent_image": ["5", 0]
        },
        "class_type": "SamplerCustomAdvanced",
        "_meta": {
          "title": "SamplerCustomAdvanced"
        }
      },
      "16": {
        "inputs": {
          "sampler_name": "euler"
        },
        "class_type": "KSamplerSelect",
        "_meta": {
          "title": "KSamplerSelect"
        }
      },
      "17": {
        "inputs": {
          "scheduler": "simple",
          "steps": 12,
          "denoise": 1,
          "model": ["61", 0]
        },
        "class_type": "BasicScheduler",
        "_meta": {
          "title": "BasicScheduler"
        }
      },
      "22": {
        "inputs": {
          "model": ["61", 0],
          "conditioning": ["60", 0]
        },
        "class_type": "BasicGuider",
        "_meta": {
          "title": "BasicGuider"
        }
      },
      "25": {
        "inputs": {
          "noise_seed": 667419872162025
        },
        "class_type": "RandomNoise",
        "_meta": {
          "title": "RandomNoise"
        }
      },
      "60": {
        "inputs": {
          "guidance": 3,
          "conditioning": ["6", 0]
        },
        "class_type": "FluxGuidance",
        "_meta": {
          "title": "FluxGuidance"
        }
      },
      "61": {
        "inputs": {
          "max_shift": 1.15,
          "base_shift": 0.5,
          "width": ["216", 1],
          "height": ["216", 2],
          "model": ["227", 0]
        },
        "class_type": "ModelSamplingFlux",
        "_meta": {
          "title": "ModelSamplingFlux"
        }
      },
      "147": {
        "inputs": {
          "samples": ["13", 0],
          "vae": ["228", 2]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "148": {
        "inputs": {
          "filename_prefix": "linkedin_headshot",
          "images": ["147", 0]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "Save Image"
        }
      },
      "216": {
        "inputs": {
          "aspect_ratio": "2:3"
        },
        "class_type": "SDXLAspectRatioSelector",
        "_meta": {
          "title": "SDXL Aspect Ratio"
        }
      },
      "223": {
        "inputs": {
          "pulid_file": "pulid_flux_v0.9.0.safetensors"
        },
        "class_type": "PulidFluxModelLoader",
        "_meta": {
          "title": "Load PuLID Flux Model"
        }
      },
      "224": {
        "inputs": {},
        "class_type": "PulidFluxEvaClipLoader",
        "_meta": {
          "title": "Load Eva Clip (PuLID Flux)"
        }
      },
      "225": {
        "inputs": {
          "provider": "CUDA"
        },
        "class_type": "PulidFluxInsightFaceLoader",
        "_meta": {
          "title": "Load InsightFace (PuLID Flux)"
        }
      },
      "227": {
        "inputs": {
          "weight": 0.8,
          "start_at": 0,
          "end_at": 1,
          "model": ["228", 0],
          "pulid_flux": ["223", 0],
          "eva_clip": ["224", 0],
          "face_analysis": ["225", 0],
          "image": ["283", 0]
        },
        "class_type": "ApplyPulidFlux",
        "_meta": {
          "title": "Apply PuLID Flux"
        }
      },
      "228": {
        "inputs": {
          "ckpt_name": "flux1-dev-fp8.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
          "title": "Load Checkpoint"
        }
      },
      "237": {
        "inputs": {
          "text_input": "head",
          "task": "caption_to_phrase_grounding",
          "fill_mask": true,
          "keep_model_loaded": false,
          "max_new_tokens": 1024,
          "num_beams": 3,
          "do_sample": true,
          "output_mask_select": "",
          "seed": 653959525333125,
          "image": ["256", 0],
          "florence2_model": ["282", 0]
        },
        "class_type": "Florence2Run",
        "_meta": {
          "title": "Florence2Run"
        }
      },
      "256": {
        "inputs": {
          "upscale_method": "lanczos",
          "megapixels": 1.0,
          "image": ["281", 0]
        },
        "class_type": "ImageScaleToTotalPixels",
        "_meta": {
          "title": "Scale Image to Total Pixels"
        }
      },
      "261": {
        "inputs": {
          "index": "0",
          "batch": false,
          "data": ["237", 3]
        },
        "class_type": "Florence2toCoordinates",
        "_meta": {
          "title": "Florence2 Coordinates"
        }
      },
      "262": {
        "inputs": {
          "keep_model_loaded": true,
          "individual_objects": false,
          "sam2_model": ["263", 0],
          "image": ["256", 0],
          "coordinates_positive": ["261", 0],
          "bboxes": ["261", 1]
        },
        "class_type": "Sam2Segmentation",
        "_meta": {
          "title": "Sam2Segmentation"
        }
      },
      "263": {
        "inputs": {
          "model": "sam2_hiera_base_plus.safetensors",
          "segmentor": "single_image",
          "device": "cuda",
          "precision": "fp16"
        },
        "class_type": "DownloadAndLoadSAM2Model",
        "_meta": {
          "title": "(Down)Load SAM2Model"
        }
      },
      "268": {
        "inputs": {
          "text_input": "",
          "task": "more_detailed_caption",
          "fill_mask": true,
          "keep_model_loaded": false,
          "max_new_tokens": 1024,
          "num_beams": 3,
          "do_sample": true,
          "output_mask_select": "",
          "seed": 918338609741451,
          "image": ["281", 0],
          "florence2_model": ["282", 0]
        },
        "class_type": "Florence2Run",
        "_meta": {
          "title": "Florence2Run"
        }
      },
      "270": {
        "inputs": {
          "text": "Sharp headshot against a clean white backdrop.  Business professional attire, neutral tones.  Natural light, direct,  modern.",
          "old": "[caption]",
          "new": ["268", 2]
        },
        "class_type": "Replace Text _O",
        "_meta": {
          "title": "Replace Text _O"
        }
      },
      "277": {
        "inputs": {
          "size": "custom",
          "custom_width": ["278", 0],
          "custom_height": ["278", 1],
          "color": "#fff"
        },
        "class_type": "LayerUtility: ColorImage V2",
        "_meta": {
          "title": "LayerUtility: ColorImage V2"
        }
      },
      "278": {
        "inputs": {
          "image": ["283", 0]
        },
        "class_type": "easy imageSize",
        "_meta": {
          "title": "ImageSize"
        }
      },
      "281": {
        "inputs": {
          "invert_mask": true,
          "blend_mode": "normal",
          "opacity": 100,
          "background_image": ["277", 0],
          "layer_image": ["283", 0]
        },
        "class_type": "LayerUtility: ImageBlend V2",
        "_meta": {
          "title": "LayerUtility: ImageBlend V2"
        }
      },
      "282": {
        "inputs": {
          "model": "microsoft/Florence-2-base",
          "precision": "fp16",
          "attention": "sdpa"
        },
        "class_type": "DownloadAndLoadFlorence2Model",
        "_meta": {
          "title": "DownloadAndLoadFlorence2Model"
        }
      },
      "283": {
        "inputs": {
          "supabase_url": "https://qwcxcdcponxctenncila.supabase.co",
          "supabase_key": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InF3Y3hjZGNwb254Y3Rlbm5jaWxhIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTU3Nzk2OTYsImV4cCI6MjA3MTM1NTY5Nn0.CW24DqG4MyD0XzNxflLSXOreHPQ7zHE5AuLV0y0iY3A",
          "table_name": "event_output_images",
          "image_column": "image_url",
          "id_column": "unique_id",
          "unique_id": ""
        },
        "class_type": "SupabaseTableWatcherNode",
        "_meta": {
          "title": "Supabase Table Watcher"
        }
      },
      "284": {
        "inputs": {
          "unique_id": ["283", 2],
          "supabase_url": "https://qwcxcdcponxctenncila.supabase.co",
          "supabase_key": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InF3Y3hjZGNwb254Y3Rlbm5jaWxhIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTU3Nzk2OTYsImV4cCI6MjA3MTM1NTY5Nn0.CW24DqG4MyD0XzNxflLSXOreHPQ7zHE5AuLV0y0iY3A",
          "bucket": "outputimages",
          "base_file_name": "image",
          "table_name": "event_output_images",
          "unique_id_column": "unique_id",
          "table_column": "output",
          "image": ["147", 0]
        },
        "class_type": "SupabaseImageUploader",
        "_meta": {
          "title": "Upload Image to Supabase"
        }
      }
    }